---
title: "Getting data from the web"
author: "Nhu Nguyen"
date: "2023-10-18"
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)

library(rvest)
library(httr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## scrape a table 

I want the first table from [this page](http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm)

read in the html 
```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_html = read_html(url)

drug_use_html
```

extract the table(s); focus on the first one 

```{r}
drug_use_html |>
  html_table()
```
```{r}
table_marj = 
  drug_use_html %>% 
  html_table() %>% 
  first() %>% 
  slice(-1) %>% 
  as.tibble()
```

## star wars moving info 

I want the data from [here](https://www.imdb.com/list/ls070150896/)

```{r}
url1 = "https://www.imdb.com/list/ls070150896/"

swm_html = read_html(url1)
```

grab elements that I want 

```{r}
title_vec = 
  swm_html %>% 
  html_elements(".lister-item-header a") %>% 
  html_text()

gross_rev_vec = 
  swm_html %>% 
  html_elements(".text-muted .ghost~ .text-muted+ span") %>% 
  html_text()

runtime_vec = 
  swm_html %>% 
  html_elements(".runtime") %>% 
  html_text()

swm_df = 
  tibble(
    title = title_vec,
    gross_rev = gross_rev_vec,
    runtime = runtime_vec)
```

## get some nyc water data 

this is coming from an API 

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")

nyc_water2 = 
 GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") %>% 
  content("text") %>% 
  jsonlite::fromJSON() %>% 
  as_tibble()
```
## brffs dataset 

same process, different data

```{r}
brffs_2010 = 
  GET("https://data.cdc.gov/resource/acme-vg9e.csv",
    query = list("$limit" = 5000))%>% 
  content("parsed")
```

## some data aren't so nice

let's look at Pokemon

```{r}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") |>
  content()

poke$name
poke$height
poke$abilities

```

## closing thoughts 

  - easy to make data requests that are unreasonable when scraping data from APIs 
  - if using a dataset ALOT, it is easier to have just 1 rmarkdown file to specify how I access and processed the data 
    - any other analysis I do can be in a different rmarkdown file -- makes it so that I don't have to go to the internet everytime and ask for data to be brought in
    
    - be responsible!!! can accidentally crash a server 




